"""
ç¯å¢ƒæ£€æŸ¥è„šæœ¬

æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒæ˜¯å¦æ»¡è¶³è¿è¡Œè¦æ±‚
"""

import sys
import platform
import subprocess
from pathlib import Path

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    version = sys.version_info
    print(f"ğŸ Pythonç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")
    
    if version.major == 3 and version.minor >= 10:
        print("   âœ… Pythonç‰ˆæœ¬æ»¡è¶³è¦æ±‚ (>= 3.10)")
        return True
    else:
        print(f"   âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦ >= 3.10")
        return False

def check_cuda():
    """æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨"""
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        
        if cuda_available:
            print(f"ğŸ® CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"   GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
            
            # æ˜¾å­˜ä¿¡æ¯
            mem_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"   æ˜¾å­˜å¤§å°: {mem_total:.1f} GB")
            
            if mem_total >= 8:
                print("   âœ… æ˜¾å­˜æ»¡è¶³è¦æ±‚ (>= 8GB)")
                return True
            else:
                print(f"   âš ï¸  æ˜¾å­˜è¾ƒå° ({mem_total:.1f}GB)ï¼Œå»ºè®®ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
                return True
        else:
            print("ğŸ® CUDA: ä¸å¯ç”¨")
            print("   âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
            return True
            
    except ImportError:
        print("ğŸ® CUDA: æœªå®‰è£…PyTorch")
        print("   âš ï¸  è¯·å…ˆå®‰è£…: pip install torch")
        return False

def check_disk_space():
    """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
    project_dir = Path(__file__).parent.parent
    
    try:
        if platform.system() == "Windows":
            import ctypes
            free_bytes = ctypes.c_ulonglong(0)
            ctypes.windll.kernel32.GetDiskFreeSpaceExW(
                str(project_dir), None, None, ctypes.pointer(free_bytes)
            )
            free_gb = free_bytes.value / 1024**3
        else:
            stat = os.statvfs(project_dir)
            free_gb = (stat.f_bavail * stat.f_frsize) / 1024**3
        
        print(f"ğŸ’¾ å¯ç”¨ç£ç›˜ç©ºé—´: {free_gb:.1f} GB")
        
        if free_gb >= 20:
            print("   âœ… ç£ç›˜ç©ºé—´å……è¶³ (>= 20GB)")
            return True
        else:
            print(f"   âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå»ºè®®è‡³å°‘20GB")
            return False
            
    except Exception as e:
        print(f"ğŸ’¾ ç£ç›˜ç©ºé—´: æ— æ³•æ£€æµ‹")
        return True

def check_dependencies():
    """æ£€æŸ¥å…³é”®ä¾èµ–æ˜¯å¦å®‰è£…"""
    print("\nğŸ“¦ æ£€æŸ¥å…³é”®ä¾èµ–:")
    
    dependencies = {
        "torch": "PyTorch",
        "transformers": "Transformers",
        "langchain": "LangChain",
        "fastapi": "FastAPI",
        "chromadb": "ChromaDB",
    }
    
    all_installed = True
    for module, name in dependencies.items():
        try:
            __import__(module)
            print(f"   âœ… {name}")
        except ImportError:
            print(f"   âŒ {name} (æœªå®‰è£…)")
            all_installed = False
    
    if not all_installed:
        print("\nğŸ’¡ å®‰è£…ä¾èµ–:")
        print("   pip install -r requirements.txt")
    
    return all_installed

def check_model():
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
    model_dir = Path(__file__).parent.parent / "models" / "chatglm3-6b"
    
    if model_dir.exists() and (model_dir / "config.json").exists():
        print(f"\nğŸ¤– æ¨¡å‹: å·²ä¸‹è½½")
        print(f"   ğŸ“ {model_dir}")
        return True
    else:
        print(f"\nğŸ¤– æ¨¡å‹: æœªä¸‹è½½")
        print("   ğŸ’¡ è¿è¡Œ: python scripts/download_model.py")
        return False

def check_data():
    """æ£€æŸ¥æ•°æ®æ˜¯å¦å·²å‡†å¤‡"""
    data_dir = Path(__file__).parent.parent / "data"
    
    stocks_exist = (data_dir / "stocks").exists() and \
                   len(list((data_dir / "stocks").glob("*.parquet"))) > 0
    
    knowledge_exist = (data_dir / "knowledge" / "basics").exists()
    
    vectordb_exist = (data_dir / "vector_db").exists()
    
    print("\nğŸ“Š æ•°æ®çŠ¶æ€:")
    print(f"   {'âœ…' if stocks_exist else 'âŒ'} è‚¡ç¥¨æ•°æ®")
    print(f"   {'âœ…' if knowledge_exist else 'âŒ'} çŸ¥è¯†åº“")
    print(f"   {'âœ…' if vectordb_exist else 'âŒ'} å‘é‡æ•°æ®åº“")
    
    if not stocks_exist:
        print("   ğŸ’¡ è¿è¡Œ: python scripts/download_stock_data.py")
    if not vectordb_exist:
        print("   ğŸ’¡ è¿è¡Œ: python scripts/build_vectordb.py")
    
    return stocks_exist and knowledge_exist and vectordb_exist

def main():
    """ä¸»å‡½æ•°"""
    print()
    print("=" * 60)
    print("ğŸ” ç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    print()
    
    checks = [
        ("Pythonç‰ˆæœ¬", check_python_version()),
        ("CUDA/GPU", check_cuda()),
        ("ç£ç›˜ç©ºé—´", check_disk_space()),
    ]
    
    # å¦‚æœåŸºç¡€ç¯å¢ƒOKï¼Œæ£€æŸ¥ä¾èµ–å’Œæ•°æ®
    if all(result for _, result in checks):
        checks.append(("ä¾èµ–åŒ…", check_dependencies()))
        checks.append(("æ¨¡å‹æ–‡ä»¶", check_model()))
        checks.append(("æ•°æ®æ–‡ä»¶", check_data()))
    
    print()
    print("=" * 60)
    print("ğŸ“‹ æ£€æŸ¥ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    for name, result in checks:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {name:15} {status}")
    
    print()
    
    if all(result for _, result in checks):
        print("ğŸ‰ ç¯å¢ƒæ£€æŸ¥å…¨éƒ¨é€šè¿‡ï¼å¯ä»¥å¼€å§‹ä½¿ç”¨ç³»ç»Ÿã€‚")
        print()
        print("ğŸš€ å¯åŠ¨æœåŠ¡:")
        print("   python server/start_server.py")
        return 0
    else:
        print("âš ï¸  éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºä¿®å¤ã€‚")
        return 1

if __name__ == "__main__":
    sys.exit(main())
